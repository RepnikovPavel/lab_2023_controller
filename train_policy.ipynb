{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pprint\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from aml.plotting import TensorBoard, get_time,plot_to_image,bar_plot\n",
    "import config\n",
    "from SearchAlg.genetic_alg_general_functions import get_L, GetPhysicalLoss\n",
    "\n",
    "from WinTermHelpers.query_helpers import *\n",
    "from FileSystem.general_purpose_functions import *\n",
    "from Alg.solving_algorithm import ModelGenerator\n",
    "from FileSystem.storage import PStorage, SimResultsManager\n",
    "from CustomModels.my_models import DistrMaker\n",
    "from CustomModels.my_models import Integrator\n",
    "import config\n",
    "from general import plot_policy_function, plot_trajectories,get_sim_results,plot_policy_function_with_trajectories\n",
    "from Simulation.sim_supp import make_psi, make_simulation_for_one_policy_function\n",
    "import sys\n",
    "from general_purpose_functions import time_mesuament\n",
    "from inc_random_descent import insert_noise_to_p\n",
    "import matplotlib.pyplot as plt\n",
    "from config import theta_v_range, omega_v_range, F_v_range\n",
    "from tqdm import tqdm\n",
    "from numba import jit\n",
    "from aml.plotting import *\n",
    "import copy\n",
    "\n",
    "from general import plot_rect\n",
    "from matplotlib import cm\n",
    "\n",
    "def WMA(arr_):\n",
    "    N = len(arr_)\n",
    "    weights = np.arange(start=1, stop=N+1, step=1)\n",
    "    weights = 2/(N*(N+1))*weights\n",
    "    return np.ma.average(a=arr_, weights=weights)\n",
    "\n",
    "def SMA(arr_):\n",
    "    N = len(arr_)\n",
    "    weights = np.ones(shape=(N,))\n",
    "    weights = 1/N*weights\n",
    "    return np.ma.average(a=arr_, weights=weights)\n",
    "\n",
    "\n",
    "def get_averaged_arr(arr_, window_size):\n",
    "    N = len(arr_)\n",
    "    av_arr_ = np.zeros(shape=(N,))\n",
    "    for i in range(N):\n",
    "        if i+1 < window_size:\n",
    "            av_arr_[i] = WMA(arr_[:i + 1])\n",
    "        else:\n",
    "            av_arr_[i] = WMA(arr_[(i + 1) - window_size:i + 1])\n",
    "\n",
    "    return av_arr_\n",
    "def get_moving_std(arr_, arr_mean_, window_size):\n",
    "    N = len(arr_)\n",
    "    o_ = np.zeros(shape=(N,))\n",
    "    delta = np.square(arr_ - arr_mean_)\n",
    "\n",
    "    for i in range(N):\n",
    "        if i+1 < window_size:\n",
    "            o_[i] = np.sqrt(1/(window_size)*np.sum(delta[:i + 1]))\n",
    "        else:\n",
    "            o_[i] = np.sqrt(1/(window_size)*np.sum(delta[(i + 1) - window_size:i + 1]))\n",
    "    return o_\n",
    "\n",
    "def get_prediction_at_last_i(arr_, i, x_,window_size):\n",
    "    o_ = -99999\n",
    "    if i+1 < window_size:\n",
    "        data_ = arr_[:i + 1]\n",
    "        x_data =  x_[:i + 1]\n",
    "        [b,a] = coefficient_reg_stat(x_data,data_)\n",
    "        # print([b,a])\n",
    "        if a  == 0 :\n",
    "            return -1\n",
    "        o_ = -b/a\n",
    "    else:\n",
    "        data_ = arr_[(i + 1) - window_size:i + 1]\n",
    "        x_data = x_[(i + 1) - window_size:i + 1]\n",
    "        [b,a] = coefficient_reg_stat(x_data,data_)\n",
    "        if a == 0:\n",
    "            return -1\n",
    "        o_ = -b/a\n",
    "    return int(o_)\n",
    "\n",
    "def plot_random_policy(func, x1grid,x2grid):\n",
    "    fig,ax = plt.subplots()\n",
    "    fig.set_size_inches(16,9)\n",
    "    \n",
    "    x = []\n",
    "    y = []\n",
    "    rects_info = []\n",
    "    highs = []\n",
    "    num_of_points_in_plot = 0\n",
    "    # в этом случае передали surf\n",
    "    for i in range(len(x1grid)-1):\n",
    "        for j in range(len(x2grid)-1):\n",
    "            x_1 = x1grid[i]\n",
    "            x_2 = x1grid[i+1]\n",
    "            y_1 = x2grid[j]\n",
    "            y_2 = x2grid[j+1]\n",
    "            x.append((x_2 + x_1) / 2)\n",
    "            y.append((y_2 + y_1) / 2)\n",
    "            rects_info.append([x_1, x_2, y_1, y_2])\n",
    "            expectation = np.mean([func((x_2 + x_1) / 2, (y_2 + y_1) / 2) for k in range(100)])\n",
    "            highs.append(expectation)\n",
    "            num_of_points_in_plot += 1\n",
    "    norm = matplotlib.colors.Normalize(vmin=min(highs), vmax=max(highs))\n",
    "    m = cm.ScalarMappable(norm=norm, cmap=cm.viridis)\n",
    "    tmp_len = len(rects_info)\n",
    "    for i in range(len(rects_info)):\n",
    "        print(\"\\r interation {} of {}\".format(i, tmp_len), end='')\n",
    "        plot_rect(ax, rects_info[i][0], rects_info[i][1], rects_info[i][2], rects_info[i][3],\n",
    "                    m.to_rgba(highs[i]))\n",
    "\n",
    "    plt.colorbar(m, ax=ax)\n",
    "    ax.set_xlim([-1.0, 1.0])\n",
    "    ax.set_ylim([-1.0, 1.0])\n",
    "    ax.set_xlabel(r\"$\\theta, \\: V$\")\n",
    "    ax.set_ylabel(r'$\\omega, \\: V$')\n",
    "    ax.set_title(r'$F, \\: V $')\n",
    "    return fig,ax\n",
    "\n",
    "def plot_trajectories_at_axis(ax, trajectories,colors,alpha):\n",
    "    for i in range(len(trajectories)):\n",
    "        tr = trajectories[i]\n",
    "        th = tr[:,0]\n",
    "        omega = tr[:,1]\n",
    "        ax.plot(th,omega,c=colors[i],alpha=alpha[i])\n",
    "    return ax\n",
    "\n",
    "\n",
    "@jit(nopython=True)\n",
    "def search_position_on_grid(grid:np.array,value:float)->int:\n",
    "    # return segment index to which balue belongs\n",
    "    N = len(grid)\n",
    "    for i in range(N-1):\n",
    "        if value >= grid[i] and value <= grid[i+1]:\n",
    "            return i\n",
    "\n",
    "\n",
    "def make_psi_from_policy_matrix(PI_,s1_grid,s2_grid,a1_values,N1,N2,M,translators_units_of_measurement,stat_decision='random'):\n",
    "\n",
    "    if stat_decision == 'mean':\n",
    "        def policy_func(x_1:float,x_2:float) -> float:\n",
    "            # input [-1,1] \\times [-1,1]\n",
    "            # output [-1,1]\n",
    "            k1 = search_position_on_grid(s1_grid,x_1)\n",
    "            k2 = search_position_on_grid(s2_grid,x_2)\n",
    "            i_ =  N2*k1 + k2\n",
    "            # return np.random.choice(a1_values,p=PI_[i_])\n",
    "            # return a1_values[np.argmax(PI_[i_])]\n",
    "            return np.sum(a1_values*PI_[i_])\n",
    "        return make_psi(policy_func,translators_units_of_measurement)    \n",
    "    elif stat_decision == 'argmax':\n",
    "        def policy_func(x_1:float,x_2:float) -> float:\n",
    "            # input [-1,1] \\times [-1,1]\n",
    "            # output [-1,1]\n",
    "            k1 = search_position_on_grid(s1_grid,x_1)\n",
    "            k2 = search_position_on_grid(s2_grid,x_2)\n",
    "            i_ =  N2*k1 + k2\n",
    "            # return np.random.choice(a1_values,p=PI_[i_])\n",
    "            return a1_values[np.argmax(PI_[i_])]\n",
    "            # return np.sum(a1_values*PI_[i_])\n",
    "        return make_psi(policy_func,translators_units_of_measurement)    \n",
    "    elif stat_decision == 'random':\n",
    "        def policy_func(x_1:float,x_2:float) -> float:\n",
    "            # input [-1,1] \\times [-1,1]\n",
    "            # output [-1,1]\n",
    "            k1 = search_position_on_grid(s1_grid,x_1)\n",
    "            k2 = search_position_on_grid(s2_grid,x_2)\n",
    "            i_ =  N2*k1 + k2\n",
    "            return np.random.choice(a1_values,p=PI_[i_])\n",
    "            # return a1_values[np.argmax(PI_[i_])]\n",
    "            # return np.sum(a1_values*PI_[i_])\n",
    "        return make_psi(policy_func,translators_units_of_measurement)    \n",
    "\n",
    "\n",
    "def make_voltage_psi_from_policy_matrix(PI_,s1_grid,s2_grid,a1_values,N1,N2,M,stat_decision='random'):\n",
    "    if stat_decision == 'mean':\n",
    "        def policy_func(x_1:float,x_2:float) -> float:\n",
    "            # input [-1,1] \\times [-1,1]\n",
    "            # output [-1,1]\n",
    "            k1 = search_position_on_grid(s1_grid,x_1)\n",
    "            k2 = search_position_on_grid(s2_grid,x_2)\n",
    "            i_ =  N2*k1 + k2\n",
    "            # return np.random.choice(a1_values,p=PI_[i_])\n",
    "            # return a1_values[np.argmax(PI_[i_])]\n",
    "            return np.sum(a1_values*PI_[i_])\n",
    "        return policy_func\n",
    "    elif stat_decision == 'argmax':\n",
    "        def policy_func(x_1:float,x_2:float) -> float:\n",
    "            # input [-1,1] \\times [-1,1]\n",
    "            # output [-1,1]\n",
    "            k1 = search_position_on_grid(s1_grid,x_1)\n",
    "            k2 = search_position_on_grid(s2_grid,x_2)\n",
    "            i_ =  N2*k1 + k2\n",
    "            # return np.random.choice(a1_values,p=PI_[i_])\n",
    "            return a1_values[np.argmax(PI_[i_])]\n",
    "            # return np.sum(a1_values*PI_[i_])\n",
    "        return policy_func\n",
    "    elif stat_decision == 'random':\n",
    "        def policy_func(x_1:float,x_2:float) -> float:\n",
    "            # input [-1,1] \\times [-1,1]\n",
    "            # output [-1,1]\n",
    "            k1 = search_position_on_grid(s1_grid,x_1)\n",
    "            k2 = search_position_on_grid(s2_grid,x_2)\n",
    "            i_ =  N2*k1 + k2\n",
    "            return np.random.choice(a1_values,p=PI_[i_])\n",
    "            # return a1_values[np.argmax(PI_[i_])]\n",
    "            # return np.sum(a1_values*PI_[i_])\n",
    "        return policy_func\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@jit(nopython = True)\n",
    "def make_init_PI(N1,N2,M):\n",
    "    # PI = np.ones(shape=(N1*N2,M),dtype=np.float32)/M\n",
    "    PI = np.ones(shape=(N1*N2,M),dtype=np.float32)/M\n",
    "    # for i in range(N1*N2):\n",
    "        # PI[i] = np.random.uniform(low=0.001,high=1.0,size=M)\n",
    "        # PI[i] = PI[i]/np.sum(PI[i]) \n",
    "    return PI\n",
    "\n",
    "@jit(nopython = True)\n",
    "def make_new_PI(old_PI:np.array,lambda_:float,alpha_:float,\n",
    "                 N1:int,N2:int,M:int,s1_grid:np.array,\n",
    "                 s2_grid:np.array, a1_grid:np.array,\n",
    "                 tr:np.array, ac:np.array)->np.array:\n",
    "    # PI = np.ones(shape=(N1*N2,M),dtype=np.float32)/M\n",
    "    # PI = np.ones(shape=(N1*N2,M),dtype=np.float32)/M\n",
    "    PI = np.copy(old_PI)\n",
    "    # for i in range(N1*N2):\n",
    "        # PI[i] = np.random.uniform(low=0.001,high=1.0,size=M)\n",
    "        # PI[i] = PI[i]/np.sum(PI[i]) \n",
    "\n",
    "    # n_of_empty_states=  0\n",
    "    for i in range(N1*N2):\n",
    "        k1 = i // N2\n",
    "        k2 = i - N2*k1\n",
    "        p1_vec = np.zeros(shape=(M,),dtype=np.intc)\n",
    "        p2_vec = np.zeros(shape=(M,),dtype=np.intc)\n",
    "        for j in range(M):\n",
    "            # count action[j] values and state[i] in elite trajectories\n",
    "            p1 = 0\n",
    "            p2 = 0\n",
    "            for t in range(len(tr)):\n",
    "                th = tr[t][0]\n",
    "                omega = tr[t][1]\n",
    "                a = ac[t]\n",
    "                # state_hit = (th >= s1_grid[k1] and th <= s1_grid[k1+1]) and (omega >= s2_grid[k2] and omega <= s2_grid[k2+1])\n",
    "                # action_hit = (a>=a1_grid[j] and a <= a1_grid[j+1])\n",
    "                # if state_hit and action_hit:\n",
    "                #     p1 +=1 \n",
    "                # if state_hit:\n",
    "                #     p2 += 1            \n",
    "                state_hit = int((th >= s1_grid[k1] and th <= s1_grid[k1+1]) and (omega >= s2_grid[k2] and omega <= s2_grid[k2+1]))\n",
    "                action_hit = int((a>=a1_grid[j] and a <= a1_grid[j+1]))\n",
    "                p1 += state_hit*action_hit \n",
    "                p2 += state_hit\n",
    "            p1_vec[j] = p1\n",
    "            p2_vec[j] = p2\n",
    "        # fig_i, ax_i = plot_float_distribution(p1_vec,fig_size=(5,5),title=str(i))\n",
    "        # if np.sum(p1_vec) == 0:\n",
    "        #     print('empty states')\n",
    "        #     raise SystemExit\n",
    "\n",
    "        # 0\n",
    "        # if np.sum(p1_vec) != 0:\n",
    "        #     PI[i] = p1_vec\n",
    "        #     PI[i] = PI[i]/np.sum(PI[i])\n",
    "\n",
    "        \n",
    "        # 1\n",
    "        # PI[i] = (p1_vec+lambda_)/(p2_vec+lambda_*M)\n",
    "        # PI[i] = PI[i]/np.sum(PI[i])\n",
    "\n",
    "        # 2\n",
    "        where_p1_zero = p1_vec == 0\n",
    "        num_of_zeros = np.sum(where_p1_zero)\n",
    "        if num_of_zeros == 0:\n",
    "            PI[i] = p1_vec/p2_vec\n",
    "            PI[i] = PI[i]/np.sum(PI[i])\n",
    "        elif num_of_zeros != M:\n",
    "            where_p1_not_zero = p1_vec != 0\n",
    "            PI[i][where_p1_not_zero] = p1_vec[where_p1_not_zero]/p2_vec[where_p1_not_zero]\n",
    "            PI[i][where_p1_not_zero] = (1-alpha_)*PI[i][where_p1_not_zero]/np.sum(PI[i][where_p1_not_zero])\n",
    "            PI[i][where_p1_zero] = alpha_ /np.sum(where_p1_zero)\n",
    "\n",
    "        # 3\n",
    "        # where_p1_not_zero = p1_vec != 0\n",
    "        # PI[i][where_p1_not_zero] = p1_vec[where_p1_not_zero]/p2_vec[where_p1_not_zero]\n",
    "        # PI[i][where_p1_not_zero] = (1-alpha_)*PI[i][where_p1_not_zero]/np.sum(PI[i][where_p1_not_zero])\n",
    "        # PI[i][where_p1_zero] = alpha_ /np.sum(where_p1_zero)\n",
    "\n",
    "    # raise SystemExit    \n",
    "    return PI\n",
    "\n",
    "\n",
    "@jit(nopython = True)\n",
    "def get_index_of_state_by_state(s1_grid,s2_grid,N1,N2,x_1,x_2)->int:\n",
    "    k1 = search_position_on_grid(s1_grid,x_1)\n",
    "    k2 = search_position_on_grid(s2_grid,x_2)\n",
    "    return N2*k1 + k2\n",
    "    \n",
    "def get_distance_from_degeneration(PI_old, PI_new, N, M, epsilon):\n",
    "    # diff_ = np.linalg.norm(PI_new-PI_old)\n",
    "    diff_ = np.sum(np.absolute(PI_old - PI_new))\n",
    "    return diff_ - epsilon*N*M\n",
    "    # diff_ = np.max(np.absolute(PI_old-PI_new))\n",
    "    # return diff_ - epsilon\n",
    "\n",
    "def coefficient_reg_stat(x, y):\n",
    "    size = len(x)\n",
    "    avg_x = sum(x)/len(x) # оценка МО величины x\n",
    "    avg_y = sum(y)/len(y) # оценка МО величины y\n",
    "    # оценка МО величины x*y\n",
    "    avg_xy = sum(x[i]*y[i] for i in range(0,size))/size\n",
    "    # оценка СКО величины x \n",
    "    std_x = (sum((x[i] - avg_x)**2 for i in range(0,size))/size)**0.5\n",
    "    # оценка СКО величины y\n",
    "    std_y = (sum((y[i] - avg_y)**2 for i in range(0,size))/size)**0.5\n",
    "    # оценка коэффициента корреляции величин x и y\n",
    "    corr_xy = (avg_xy - avg_x*avg_y)/(std_x*std_y)\n",
    "    \n",
    "    # расчет искомых коэффициентов\n",
    "    w1 = corr_xy*std_y/std_x\n",
    "    w0 = avg_y - avg_x*w1\n",
    "    return w0, w1\n",
    "def predict_linear(a,b,x):\n",
    "    return a*x+b\n",
    "\n",
    "\n",
    "@jit(nopython = True)\n",
    "def L(solution:np.array,rho_max:float,gamma:float,tau:float,t_end:float)->float:\n",
    "    theta_vec = solution[:,0]\n",
    "    omega_vec = solution[:,1]\n",
    "    T_ = len(theta_vec)\n",
    "    rho_i = np.sqrt(np.square(theta_vec) + np.square(omega_vec))\n",
    "    # theta_i = np.absolute(theta_vec)\n",
    "    # delta_rho_i = np.diff(rho_i)\n",
    "    # delta_theta_i = -np.diff(np.absolute(theta_vec))\n",
    "    # delta_omega_i = -np.diff(np.absolute(omega_vec))\n",
    "    r_vec = np.zeros(shape=(T_-1,),dtype=np.float32)\n",
    "    for t in range(1, T_):\n",
    "        r_vec[t-1] = 1/(rho_i[t]*np.absolute(t*tau/t_end)+0.001)\n",
    "        # r_vec[t-1] = -rho_i[t]*np.absolute(t*tau/t_end)\n",
    "        # r_vec[t-1] = -theta_i[t]*np.absolute(t*tau/t_end)/T_\n",
    "        # r_vec[t-1]  = (theta_i[t-1] - theta_i[t])\n",
    "    # r_vec =  r_vec*(1.0/T_)\n",
    "    r_vec =  r_vec*T_\n",
    "    # r_vec = r_vec * (1.0/theta_i[0]) \n",
    "    # simple_plot(np.arange(0,T_),rho_i,title=r'$\\rho$',size=(5,5))\n",
    "    # fig,ax = simple_plot(np.arange(1,T_),-r_vec,title=r'$loss$',size=(5,5))\n",
    "    # ax.set_xlim(0,T_-1)\n",
    "    # # simple_plot(np.arange(1,T_),delta_rho_i,title=r'$\\delta_{rho}$',size=(5,5))\n",
    "    # # plot_float_distribution(r_vec)\n",
    "    # raise SystemExit\n",
    "    return -r_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard http://localhost:64001/\n"
     ]
    }
   ],
   "source": [
    "# exp_metadata = get_time()\n",
    "board = TensorBoard(tensorboard_exe_path=config.tensorboard_path,\n",
    "                    logdir=os.path.join(config.task_dir, 'tblog'),\n",
    "                    port= '64001')\n",
    "exp_metadata = 'final_result_m_5'+get_time()\n",
    "board.InitExperiment(experiment_metadata= exp_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1 = 10\n",
    "N2 = 10\n",
    "M = 10\n",
    "lambda_ = 0.01\n",
    "alpha_0 = 0.0\n",
    "epsilon_ = 0.8\n",
    "gamma_ = 0.99\n",
    "N_ = 2000\n",
    "num_of_iterations = 50\n",
    "num_of_explorations = 20\n",
    "stat_decision = 'random'\n",
    "rho_max_ = np.sqrt(config.fuzzy_inf_params['th_max']**2 + config.fuzzy_inf_params['omega_max']**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "discretize the values of continuous quantities $theta, omega, F$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1_step = (theta_v_range[1]-theta_v_range[0])/N1 \n",
    "s2_step = (omega_v_range[1]-omega_v_range[0])/N2\n",
    "a1_step = (F_v_range[1]-F_v_range[0])/M\n",
    "\n",
    "s1_grid = np.linspace(start=theta_v_range[0],stop=theta_v_range[1],num = N1+1)\n",
    "s2_grid = np.linspace(start=omega_v_range[0],stop=omega_v_range[1],num = N2+1)\n",
    "a1_grid = np.linspace(start=F_v_range[0],stop=F_v_range[1],num = M+1)\n",
    "s1_grid_si = np.array([config.translators_units_of_measurement['from_th_in_volt_to_th_in_si'](el) for el in s1_grid],dtype=np.float32)\n",
    "s2_grid_si = np.array([config.translators_units_of_measurement['from_omega_in_volt_to_omega_in_si'](el) for el in s2_grid],dtype=np.float32)\n",
    "a1_grid_si = np.array([config.translators_units_of_measurement['from_v_in_volt_to_v_in_si'](el) for el in a1_grid],dtype=np.float32)\n",
    "s1_values = np.arange(start = theta_v_range[0]+s1_step/2,stop=theta_v_range[1],step= s1_step)\n",
    "s2_values = np.arange(start = omega_v_range[0]+s2_step/2,stop=omega_v_range[1],step= s2_step)\n",
    "a1_values = np.arange(start = F_v_range[0]+a1_step/2,stop=F_v_range[1],step= a1_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "set initial policy matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PI = make_init_PI(N1,N2,M)\n",
    "PI = torch.load(os.path.join(config.task_dir,'policy_ml.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make start points set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S_0 = []\n",
    "for i in range(N1):\n",
    "    for j in range(N2):\n",
    "        S_0.append((s1_values[i],s2_values[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_loss_vec = []\n",
    "current_best_loss = 999999\n",
    "current_best_PI = np.copy(PI)\n",
    "all_states_indexes_list = np.arange(0,len(S_0))\n",
    "# deg_vs = np.zeros(shape=(num_of_iterations,),dtype=np.float32)\n",
    "dists_to_deg = []\n",
    "current_iter_for_deg_compute = []\n",
    "expectation_of_total_loss_per_start_state = {i:0.0 for i in all_states_indexes_list}\n",
    "distribution_of_start_states = np.ones(shape=(N1*N2,), dtype = np.float32)/(N1*N2)\n",
    "n = 0 \n",
    "# for n in range(num_of_iterations):\n",
    "number_of_completed_explorations = -1\n",
    "while True:\n",
    "# for n in range(num_of_iterations):\n",
    "    # print('iteration {}/{}'.format(n+1,num_of_iterations))\n",
    "    # sample trajectories\n",
    "    psi = make_psi_from_policy_matrix(PI, s1_grid,s2_grid,a1_values,N1,N2,M,config.translators_units_of_measurement,stat_decision=stat_decision)\n",
    "\n",
    "    condition_of_break = np.asarray([\n",
    "        config.theta_range,\n",
    "        config.omega_range,\n",
    "        [-9999.0, 9999.0],\n",
    "        [-9999.0, 9999.0]\n",
    "    ])\n",
    "    simulation = make_simulation_for_one_policy_function(\n",
    "        psi=psi,\n",
    "        phys_sim_params=config.phys_sim_params,\n",
    "        condition_of_break=condition_of_break,\n",
    "        object_params=config.phys_params,\n",
    "        use_an_early_stop=False,\n",
    "        action_check=False\n",
    "        \n",
    "    )\n",
    "    # T = config.phys_sim_params['t_end']\n",
    "    T = 2.0\n",
    "    tau = config.phys_sim_params['tau']\n",
    "    y_0 = config.phys_sim_params['y_0']\n",
    "    v_0 = config.phys_sim_params['v_0']\n",
    "\n",
    "    from_th_in_volt_to_th_in_si = config.translators_units_of_measurement['from_th_in_volt_to_th_in_si']\n",
    "    from_omega_in_volt_to_omega_in_si = config.translators_units_of_measurement['from_omega_in_volt_to_omega_in_si']\n",
    "    trajectories = []\n",
    "    actions = []\n",
    "    L_vec = np.zeros(shape=(N1*N2+N_,),dtype=np.float32)\n",
    "    \n",
    "    states_indexes = np.zeros(shape=(N1*N2+N_,),dtype=np.intc)\n",
    "    Loss_per_pairs = []\n",
    "\n",
    "    \n",
    "    for i in range(N1*N2+N_):\n",
    "        # get trajectory, get loss\n",
    "        state_index = -1\n",
    "        if i <= N1*N2-1:\n",
    "            state_index = i\n",
    "        else:\n",
    "            # print(distribution_of_start_states)\n",
    "            # print(np.sum(distribution_of_start_states))\n",
    "            state_index = np.random.choice(all_states_indexes_list,p=distribution_of_start_states)\n",
    "        states_indexes[i] = state_index\n",
    "        s_0 = S_0[state_index]\n",
    "        code_of_sim, solution, time_of_simulation, control_actions = simulation(\n",
    "                                                                        from_th_in_volt_to_th_in_si(s_0[0]),\n",
    "                                                                        from_omega_in_volt_to_omega_in_si(s_0[1]),\n",
    "                                                                        y_0, v_0)\n",
    "        solution = solution[:-1,:]\n",
    "        control_actions = control_actions[1:]\n",
    "        loss_for_pairs = L(solution,rho_max= rho_max_, gamma=gamma_,tau=tau,t_end=time_of_simulation)\n",
    "        Loss_per_pairs.append(loss_for_pairs)\n",
    "        # loss for pairs can be empty,bacause len(solution) can be 1. (zero state -> action -> out of bounds)\n",
    "        L_vec[i] = np.sum(loss_for_pairs)\n",
    "        # total_loss_per_start_state[state_index] = L_vec[i]\n",
    "        trajectories.append(solution[:,:2])\n",
    "        actions.append(control_actions)\n",
    "\n",
    "    state_count = {i:0 for i in np.unique(states_indexes)}\n",
    "    state_positions = {i:0 for i in np.unique(states_indexes)}\n",
    "    trajectories_by_states = []\n",
    "    for i in range(N1*N2+N_):\n",
    "        state_count[states_indexes[i]]+=1\n",
    "    for state_index in state_positions.keys():\n",
    "        state_positions[state_index] = np.argwhere(states_indexes==state_index).flatten()\n",
    "    \n",
    "    Tr_elite = [] \n",
    "    A_elite = []\n",
    "\n",
    "    if len(np.setdiff1d(all_states_indexes_list, list(state_positions.keys()))) !=0 :\n",
    "           print('not all possible states in dataset')\n",
    "           print('this states not in dataset')\n",
    "           print(np.setdiff1d(all_states_indexes_list, list(state_positions.keys())))\n",
    "           raise SystemExit\n",
    "    for state_index in state_positions.keys():\n",
    "        if state_count[state_index] == 0:\n",
    "            print('state not in dataset. state index {}'.format(state_index))\n",
    "            raise SystemExit\n",
    "        if state_count[state_index] >= 1:\n",
    "            state_trajectories = []\n",
    "            state_losses = []\n",
    "            state_actions = []\n",
    "            # for state_pos in state_positions[state_index]:\n",
    "            #     state_pos_ = state_pos[0]\n",
    "            #     state_trajectories.append(trajectories[state_pos_])\n",
    "            #     state_losses.append(L_vec[state_pos_])\n",
    "            #     state_actions.append(actions[state_pos_])\n",
    "\n",
    "            # # make elite trajectories like in pure cross entropy method\n",
    "            # argsort_ = np.argsort(state_losses)\n",
    "            # q = 0.1\n",
    "            # num_ = np.maximum(1, int(q*len(state_trajectories)))\n",
    "            # state_elite_tr = [state_trajectories[argsort_[j]] for j in range(num_)]\n",
    "            # state_elite_actions = [state_actions[argsort_[j]] for j in range(num_)]\n",
    "            # for i in range(len(state_elite_tr)):\n",
    "            #     Tr_elite.append(state_elite_tr[i])\n",
    "            #     A_elite.append(state_elite_actions[i])\n",
    "\n",
    "            ## make elite pairs (s_{t-1},a_{t}}) -> (r_{t})\n",
    "            ## dataset in form s_{i},a_{i} -> r_{i}\n",
    "            elite_states = []\n",
    "            elite_ations = []\n",
    "\n",
    "            for state_pos_ in state_positions[state_index]:\n",
    "                if len(Loss_per_pairs[state_pos_]) < 2 :\n",
    "                    continue\n",
    "                state_trajectories.append(trajectories[state_pos_])\n",
    "                state_losses.append(Loss_per_pairs[state_pos_])\n",
    "                state_actions.append(actions[state_pos_])\n",
    "            if len(state_trajectories) == 0:\n",
    "                continue\n",
    "            all_state_losses = []\n",
    "            for i in range(len(state_trajectories)):\n",
    "                losses_= state_losses[i]\n",
    "                for j in range(len(losses_)):\n",
    "                    all_state_losses.append(losses_[j])\n",
    "            expectation_of_total_loss_per_start_state[state_index] = np.mean(all_state_losses)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            best_states_indexes = []\n",
    "            # get q-th percentile by losses (ascending order) \n",
    "            for i in range(len(state_trajectories)):\n",
    "                tr_ = state_trajectories[i]\n",
    "                ac_ = state_actions[i]\n",
    "                losses_= state_losses[i]\n",
    "                argsort_ = np.argsort(losses_)\n",
    "                q = 0.1\n",
    "                num_ = np.maximum(1, int(len(tr_)*q))\n",
    "                # print(num_)\n",
    "                best_pairs_states = [tr_[argsort_[j]] for j in range(num_)]\n",
    "                best_pairs_actions = [ac_[argsort_[j]] for j in range(num_)]\n",
    "                for j in range(len(best_pairs_states)):\n",
    "                    elite_states.append(best_pairs_states[j])\n",
    "                    elite_ations.append(best_pairs_actions[j])\n",
    "                    state_index_at_j_step = get_index_of_state_by_state(s1_grid_si,s2_grid_si,N1,N2,best_pairs_states[j][0],best_pairs_states[j][1])\n",
    "                    best_states_indexes.append(state_index_at_j_step)\n",
    "\n",
    "            # # get all with positive reward \n",
    "            # for i in range(len(state_trajectories)):\n",
    "            #     tr_ = state_trajectories[i]\n",
    "            #     ac_ = state_actions[i]\n",
    "            #     losses_= state_losses[i]\n",
    "            #     argsort_ = np.argwhere(losses_ < 0.0).flatten()\n",
    "            #     best_pairs_states = [tr_[argsort_[j]] for j in range(len(argsort_))]\n",
    "            #     best_pairs_actions = [ac_[argsort_[j]] for j in range(len(argsort_))]\n",
    "            #     for j in range(len(best_pairs_states)):\n",
    "            #         elite_states.append(best_pairs_states[j])\n",
    "            #         elite_ations.append(best_pairs_actions[j])\n",
    "            #         state_index_at_j_step = get_index_of_state_by_state(s1_grid_si,s2_grid_si,N1,N2,best_pairs_states[j][0],best_pairs_states[j][1])\n",
    "            #         best_states_indexes.append(state_index_at_j_step)\n",
    "\n",
    "\n",
    "            # get pairs wich better then another (s,a) pairs but the states \\set{s} of these pairs is not in the list of all possible states  \n",
    "            # (coverage of all states is not complete)        \n",
    "            # state_inex is index of initial state\n",
    "            unique_best_states_indexes = np.unique(best_states_indexes)\n",
    "            all_states_indexes_in_tr = []\n",
    "            unseen_losses = []\n",
    "            unseen_tr = []\n",
    "            unseen_ac = [] \n",
    "            unseen_states = []\n",
    "            for i in range(len(state_trajectories)):\n",
    "                tr_ = state_trajectories[i]\n",
    "                ac_ = state_actions[i]\n",
    "                losses_= state_losses[i]\n",
    "                for j in range(len(tr_)-1):\n",
    "                    state_index_at_j_step = get_index_of_state_by_state(s1_grid_si,s2_grid_si,N1,N2,tr_[j][0],tr_[j][1])\n",
    "                    all_states_indexes_in_tr.append(state_index_at_j_step)\n",
    "                    if state_index_at_j_step not in unique_best_states_indexes:\n",
    "                        unseen_losses.append(losses_[j])\n",
    "                        unseen_tr.append(tr_[j])\n",
    "                        unseen_ac.append(ac_[j])\n",
    "                        unseen_states.append(state_index_at_j_step)\n",
    "\n",
    "            unseen_losses = np.array(unseen_losses,dtype=np.float32)\n",
    "            unseen_tr = np.array(unseen_tr,dtype=np.float32)\n",
    "            unseen_ac = np.array(unseen_ac,dtype=np.float32)\n",
    "            unseen_states = np.array(unseen_states,dtype=np.intc)\n",
    "            # print(len(unseen_states))\n",
    "            # print(np.unique(unseen_states))\n",
    "            # raise SystemExit\n",
    "            unchoosen_states_in_trajectory = np.unique(unseen_states)\n",
    "            for unselected_state in unchoosen_states_in_trajectory:\n",
    "                where_state = np.argwhere(unseen_states == unselected_state).flatten()\n",
    "                st_ls = unseen_losses[where_state]\n",
    "                st_ac = unseen_ac[where_state]\n",
    "                st_tr = unseen_tr[where_state]\n",
    "                argsort_ = np.argsort(st_ls)\n",
    "                q = 0.1\n",
    "                num_ = np.maximum(1, int(len(st_tr)*q))\n",
    "                best_pairs_states = [st_tr[argsort_[j]] for j in range(num_)]\n",
    "                best_pairs_actions = [st_ac[argsort_[j]] for j in range(num_)]\n",
    "                # argsort_ = np.argwhere(st_ls < 0.0).flatten()\n",
    "                # best_pairs_states = [st_tr[argsort_[j]] for j in range(len(argsort_))]\n",
    "                # best_pairs_actions = [st_ac[argsort_[j]] for j in range(len(argsort_))]\n",
    "                # if len(best_pairs_actions) ==1 :\n",
    "                #     print(best_pairs_states)\n",
    "                for j in range(len(best_pairs_states)):\n",
    "                    elite_states.append(best_pairs_states[j])\n",
    "                    elite_ations.append(best_pairs_actions[j])\n",
    "                \n",
    "            if len(elite_states) !=0:\n",
    "                for j in range(len(elite_states)):\n",
    "                    Tr_elite.append(elite_states[j])\n",
    "                    A_elite.append(elite_ations[j])\n",
    "            # print('unseen states:')\n",
    "            # print(unchoosen_states_in_trajectory)\n",
    "    \n",
    "    # states_plot_ = expectation_of_total_loss_per_start_state.keys()\n",
    "    # hights_ = [expectation_of_total_loss_per_start_state[el] for el in states_plot_]\n",
    "    # bar_fig, bar_ax = bar_plot(objects=states_plot_, heights=hights_,fig_size=(16,9),title=r'$E\\mathcal{L} (s_{0})$')\n",
    "    # img_ = plot_to_image(bar_fig)\n",
    "    # board.PlotImage(experiment_metadata=exp_metadata,img=img_,label='loss per state',step = n)\n",
    "    Tr_elite = np.array(Tr_elite, dtype=np.float32)\n",
    "    A_elite = np.array(A_elite,dtype=np.float32)\n",
    "    #final check\n",
    "    all_states_in_dataset = []\n",
    "    for obs_ in Tr_elite:\n",
    "        obs_index = get_index_of_state_by_state(s1_grid_si,s2_grid_si,N1,N2,obs_[0],obs_[1])\n",
    "        all_states_in_dataset.append(obs_index)\n",
    "    all_states_in_dataset= np.unique(all_states_in_dataset)\n",
    "    if len(np.setdiff1d(all_states_indexes_list,all_states_in_dataset)) !=0 :\n",
    "        print('not all possible states in dataset')\n",
    "        print('this states not in dataset')\n",
    "        print(np.setdiff1d(all_states_indexes_list,all_states_in_dataset))\n",
    "        print('this states in dataset')\n",
    "        print(all_states_in_dataset)\n",
    "        raise SystemExit\n",
    "\n",
    "    p_loss_ = np.mean(L_vec)\n",
    "    policy_loss_vec.append(p_loss_)\n",
    "    # policy_loss_vec[n] = p_loss_\n",
    "\n",
    "    if p_loss_ <= current_best_loss:\n",
    "        current_best_PI = np.copy(PI)\n",
    "        current_best_loss = p_loss_\n",
    "    \n",
    "    # if n==0:\n",
    "    #     PI = PI_new \n",
    "    # else:\n",
    "    # alpha_t = (1-(n+1)/(num_of_iterations-1))*alpha_0\n",
    "    alpha_t = 0.0\n",
    "    PI_new = make_new_PI(PI, lambda_,alpha_t,N1,N2,M,s1_grid_si,s2_grid_si,a1_grid_si,Tr_elite,A_elite)\n",
    "    PI_new = (1-epsilon_)*PI_new + epsilon_*PI \n",
    "    dist_to_deg =  get_distance_from_degeneration(PI,PI_new,N1*N2,M,epsilon=0.001)\n",
    "    \n",
    "\n",
    "    # update distibution of start states\n",
    "    \n",
    "    losses_per_init_state = []\n",
    "    init_states_ = []\n",
    "    for init_state, loss_for_init_state in expectation_of_total_loss_per_start_state.items():\n",
    "        losses_per_init_state.append(loss_for_init_state)\n",
    "        init_states_.append(init_state)\n",
    "\n",
    "    # plot current distr of init states \n",
    "    # bar_fig, bar_ax = bar_plot(objects=init_states_, heights=distribution_of_start_states,fig_size=(16,9),title=r'$p_{n}(s_{0})}$')\n",
    "    # img_ = plot_to_image(bar_fig)\n",
    "    # board.PlotImage(experiment_metadata=exp_metadata,img=img_,label='distr of init states',step = n)\n",
    "\n",
    "    losses_per_init_state = np.array(losses_per_init_state,dtype=np.float32)\n",
    "    init_states_ = np.array(init_states_,dtype=np.intc)\n",
    "    # argsort_des = np.argsort(losses_per_init_state)[::-1]\n",
    "    inverted_losses_ = losses_per_init_state - np.min(losses_per_init_state)\n",
    "    inverted_losses_ = inverted_losses_\n",
    "    # inverted_losses_ = np.max(inverted_losses_) - inverted_losses_\n",
    "    # distr_ = 1.0/(inverted_losses_ + 0.001)\n",
    "    distr_ = None\n",
    "    if np.sum(inverted_losses_)==0.0:\n",
    "        distr_ = np.ones(shape=(N1*N2,),dtype=np.float32)*(1.0/(N1*N2))\n",
    "    else:\n",
    "        distr_ = inverted_losses_/np.sum(inverted_losses_)\n",
    "    distribution_of_start_states = distr_*(1-0.8)+distribution_of_start_states*0.8\n",
    "    distribution_of_start_states = distribution_of_start_states/np.sum(distribution_of_start_states)\n",
    "\n",
    "\n",
    "    # print(losses_per_init_state)\n",
    "    # fig1,ax1 = bar_plot(init_states_, losses_per_init_state,fig_size=(16,9),title='computed losses')\n",
    "    # fig2,ax2 = bar_plot(init_states_, inverted_losses_,fig_size=(16,9),title='inverted losses')\n",
    "    # fig3,ax3 = bar_plot(init_states_, distr_,fig_size=(16,9),title='updated distr of init states')\n",
    "    # ax1.set_yscale('log')\n",
    "    # ax2.set_yscale('log')\n",
    "    # plt.show()\n",
    "    # raise SystemExit\n",
    "    # distribution_of_start_states = \n",
    "\n",
    "    board.Push(experiment_metadata=exp_metadata,\n",
    "               x=n,y=-p_loss_, label='total reward')\n",
    "    board.Push(experiment_metadata=exp_metadata,\n",
    "            x=n,y=dist_to_deg, label='dist to deg')\n",
    "    if dist_to_deg <= 0:\n",
    "        print('stop at {} iteration'.format(n))\n",
    "        print('current loss {}'.format(p_loss_))\n",
    "        print('best loss {}'.format(current_best_loss))\n",
    "        number_of_completed_explorations += 1\n",
    "        # mix with uniform actions to explore \n",
    "        PI_new = 0.5*PI+ 0.5*np.ones(shape=(N1*N2,M),dtype=np.float32)/M\n",
    "        distribution_of_start_states = 0.5*distribution_of_start_states + 0.5*np.ones(shape=(N1*N2,),dtype=np.float32)/(N1*N2)\n",
    "        distribution_of_start_states = distribution_of_start_states/np.sum(distribution_of_start_states)\n",
    "        if number_of_completed_explorations >= num_of_explorations:\n",
    "            break\n",
    "    stop_at_predict = -1\n",
    "    current_iter_for_deg_compute.append(n)\n",
    "    dists_to_deg.append(dist_to_deg) \n",
    "    if n > 2:\n",
    "        stop_at_predict = get_prediction_at_last_i(dists_to_deg, n, current_iter_for_deg_compute\n",
    "                                                   ,window_size = 30)\n",
    "        \n",
    "    print('iteration {}. stop at {} iteration. deg dist {} \\t loss {}'.format(\n",
    "        n, stop_at_predict, str(dist_to_deg)[:6],str(p_loss_)))\n",
    "   \n",
    "    PI = PI_new\n",
    "    n = n + 1\n",
    "\n",
    "# PI = current_best_PI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_iterations = n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(PI,os.path.join(config.task_dir,'policy_ml.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(PI,os.path.join(config.task_dir,'policy_ml_backup2.txt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1,ax1 = plt.subplots()\n",
    "fig1.set_size_inches(16,9)\n",
    "im_ = ax1.imshow(PI)\n",
    "fig1.colorbar(im_, ax=ax1)\n",
    "ax1.set_xticks(np.arange(start=0,stop=len(a1_values)))\n",
    "fig1.gca().set_aspect('auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig,ax = simple_plot(np.arange(0,num_of_iterations),policy_loss_vec,title=r'$-E_{s_{0}}R$')\n",
    "fig,ax = plt.subplots()\n",
    "fig.set_size_inches(16,9)\n",
    "ax.grid()\n",
    "ax.minorticks_on()\n",
    "ax.set_title(r'$Loss = -E_{s_{0}}R$')\n",
    "ax.set_xlabel('index of iteration')\n",
    "ax.grid(which='major', color='#DDDDDD', linewidth=0.8)\n",
    "ax.grid(which='minor', color='#EEEEEE', linestyle=':', linewidth=0.5)\n",
    "m_err = get_averaged_arr(policy_loss_vec[:num_of_iterations],window_size=50)\n",
    "ax.plot(np.arange(0,num_of_iterations),m_err,'ko--', linewidth=2, markersize=6)\n",
    "m_std = get_moving_std(policy_loss_vec[:num_of_iterations], m_err,window_size=50)\n",
    "ax.fill_between(np.arange(0,num_of_iterations), m_err-m_std, m_err+m_std, color= '#eb86b1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_plot(x=np.arange(0,num_of_iterations-1),y=dists_to_deg,title='distance to convergence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PI_ = torch.load(os.path.join(config.task_dir,'policy_ml.txt'))\n",
    "# PI_ = PI\n",
    "# PI = current_best_PI\n",
    "# test_des = 'argmax'\n",
    "test_des = 'random'\n",
    "# test_des = 'mean'\n",
    "psi_v = make_voltage_psi_from_policy_matrix(PI_, s1_grid,s2_grid,a1_values,N1,N2,M,stat_decision=test_des)\n",
    "psi = make_psi_from_policy_matrix(PI_, s1_grid,s2_grid,a1_values,N1,N2,M,config.translators_units_of_measurement,stat_decision=test_des)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax= plot_random_policy(psi_v, s1_grid,s2_grid)\n",
    "condition_of_break = np.asarray([\n",
    "    config.theta_range,\n",
    "    config.omega_range,\n",
    "    [-9999.0, 9999.0],\n",
    "    [-9999.0, 9999.0]\n",
    "])\n",
    "simulation = make_simulation_for_one_policy_function(\n",
    "    psi=psi,\n",
    "    phys_sim_params=config.phys_sim_params,\n",
    "    condition_of_break=condition_of_break,\n",
    "    object_params=config.phys_params,\n",
    "    use_an_early_stop=False,\n",
    "    action_check=False\n",
    "    \n",
    ")\n",
    "T = config.phys_sim_params['t_end']\n",
    "y_0 = config.phys_sim_params['y_0']\n",
    "v_0 = config.phys_sim_params['v_0']\n",
    "\n",
    "from_th_in_volt_to_th_in_si = config.translators_units_of_measurement['from_th_in_volt_to_th_in_si']\n",
    "from_omega_in_volt_to_omega_in_si = config.translators_units_of_measurement['from_omega_in_volt_to_omega_in_si']\n",
    "from_th_in_si_to_th_in_volt = config.translators_units_of_measurement['from_th_in_si_to_th_in_volt']\n",
    "from_omega_in_si_to_omega_in_volt = config.translators_units_of_measurement['from_omega_in_si_to_omega_in_volt']\n",
    "trajectories = []\n",
    "colors = []\n",
    "alphas = []\n",
    "n_bad = 0\n",
    "n_good = 0\n",
    "L_vec_ = np.zeros(shape=(len(S_0),),dtype=np.float32)\n",
    "for i in range(len(S_0)):\n",
    "    # get trajectory, get loss\n",
    "    s_0 = S_0[i]\n",
    "    code_of_sim, solution, time_of_simulation, control_actions = simulation(\n",
    "                                                                    from_th_in_volt_to_th_in_si(s_0[0]),\n",
    "                                                                    from_omega_in_volt_to_omega_in_si(s_0[1]),\n",
    "                                                                    y_0, v_0)\n",
    "    trajectories.append(solution[:,:2])\n",
    "    actions.append(control_actions)\n",
    "    loss_for_pairs = L(solution,rho_max= rho_max_, gamma=gamma_,tau=tau,t_end=time_of_simulation)\n",
    "    # loss for pairs can be empty,bacause len(solution) can be 1. (zero state -> action -> out of bounds)\n",
    "    L_vec_[i] = np.sum(loss_for_pairs)\n",
    "    if code_of_sim == 1:\n",
    "        colors.append('r')\n",
    "        alphas.append(0.5)\n",
    "        n_bad  +=1 \n",
    "    else:\n",
    "        colors.append('k')\n",
    "        alphas.append(0.3)\n",
    "        n_good +=1 \n",
    "print('\\nbad {} good {}'.format(n_bad, n_good))\n",
    "trajectories_v = []\n",
    "for tr in trajectories:\n",
    "    tr_v = np.array([(from_th_in_si_to_th_in_volt(el[0]),from_omega_in_si_to_omega_in_volt(el[1])) for el in tr])\n",
    "    trajectories_v.append(tr_v)\n",
    "plot_trajectories_at_axis(ax,trajectories_v,colors,alphas)\n",
    "def loss_function_(x_1,x_2):\n",
    "    index_of_st_ = get_index_of_state_by_state(s1_grid,s2_grid,N1,N2,x_1=x_1,x_2=x_2)\n",
    "    return L_vec_[index_of_st_]\n",
    "fig2,ax2= plot_random_policy(loss_function_, s1_grid,s2_grid)\n",
    "ax2.set_title(r'$L(s_{0})$')\n",
    "\n",
    "def distr_of_init_states_function(x_1,x_2):\n",
    "    index_of_st_ = get_index_of_state_by_state(s1_grid,s2_grid,N1,N2,x_1=x_1,x_2=x_2)\n",
    "    return distribution_of_start_states[index_of_st_]\n",
    "fig3,ax3= plot_random_policy(distr_of_init_states_function, s1_grid,s2_grid)\n",
    "ax3.set_title(r'$P(s_{0})$')\n",
    "plt.show()\n",
    "img_ = plot_to_image(fig)\n",
    "board.PlotImage(experiment_metadata=exp_metadata, img=img_, label='response surf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# policy_loss_vec = np.zeros(shape=(num_of_iterations,))\n",
    "# last_best_loss = 99999\n",
    "# for n in tqdm(range(num_of_iterations)):\n",
    "#     # print('iteration {}/{}'.format(n+1,num_of_iterations))\n",
    "#     # sample trajectories\n",
    "#     psi = make_psi_from_policy_matrix(PI, s1_grid,s2_grid,a1_values,N1,N2,M,config.translators_units_of_measurement)\n",
    "\n",
    "#     condition_of_break = np.asarray([\n",
    "#         config.theta_range,\n",
    "#         config.omega_range,\n",
    "#         [-9999.0, 9999.0],\n",
    "#         [-9999.0, 9999.0]\n",
    "#     ])\n",
    "#     simulation = make_simulation_for_one_policy_function(\n",
    "#         psi=psi,\n",
    "#         phys_sim_params=config.phys_sim_params,\n",
    "#         condition_of_break=condition_of_break,\n",
    "#         object_params=config.phys_params,\n",
    "#         use_an_early_stop=False,\n",
    "#         action_check=False\n",
    "        \n",
    "#     )\n",
    "#     # T = config.phys_sim_params['t_end']\n",
    "#     T = 3.0\n",
    "#     tau = config.phys_sim_params['tau']\n",
    "#     y_0 = config.phys_sim_params['y_0']\n",
    "#     v_0 = config.phys_sim_params['v_0']\n",
    "\n",
    "#     from_th_in_volt_to_th_in_si = config.translators_units_of_measurement['from_th_in_volt_to_th_in_si']\n",
    "#     from_omega_in_volt_to_omega_in_si = config.translators_units_of_measurement['from_omega_in_volt_to_omega_in_si']\n",
    "#     trajectories = []\n",
    "#     actions = []\n",
    "#     L_vec = np.zeros(shape=(N_,),dtype=np.float32)\n",
    "#     current_best_loss = 999999\n",
    "#     current_best_PI = PI\n",
    "#     for i in range(N_):\n",
    "#         # get trajectory, get loss\n",
    "#         s_0 = S_0[np.random.randint(low=0,high=len(S_0))]\n",
    "#         code_of_sim, solution, time_of_simulation, control_actions = simulation(\n",
    "#                                                                         from_th_in_volt_to_th_in_si(s_0[0]),\n",
    "#                                                                         from_omega_in_volt_to_omega_in_si(s_0[1]),\n",
    "#                                                                         y_0, v_0)\n",
    "#         solution = solution[:-1,:]\n",
    "#         control_actions = control_actions[1:]\n",
    "#         loss_for_pairs = L(solution,rho_max= rho_max_, gamma=gamma_,tau=tau,t_end=T)\n",
    "#         L_vec[i] = np.sum(loss_for_pairs)\n",
    "#         trajectories.append(solution)\n",
    "#         actions.append(control_actions)\n",
    "\n",
    "#         # solution = solution[:-1,:]\n",
    "#         # control_actions = control_actions[1:]\n",
    "#         # loss_for_pairs = L(solution,rho_max= rho_max_, gamma=gamma_,tau=tau,t_end=T)\n",
    "#         # # good_pairs = loss_for_pairs <= 0.0\n",
    "#         # argsrot_for_pairs = np.argsort(loss_for_pairs)\n",
    "#         # fraction_of_objects = 0.1\n",
    "#         # best_pairs_n = int(fraction_of_objects*len(loss_for_pairs))\n",
    "#         # if best_pairs_n == 0:\n",
    "#         #     continue\n",
    "#         # best_solutions = np.array([solution[argsrot_for_pairs[k]] for k in range(best_pairs_n)])\n",
    "#         # best_actions = np.array([control_actions[argsrot_for_pairs[k]] for k in range(best_pairs_n)])\n",
    "\n",
    "#         # trajectories.append(best_solutions)\n",
    "#         # actions.append(best_actions)\n",
    "#         # L_vec[i] = np.mean(loss_for_pairs)\n",
    "\n",
    "\n",
    "\n",
    "#     # #select elite trajectories\n",
    "#     argsort_ = np.argsort(L_vec)\n",
    "#     Tr_elite = [trajectories[argsort_[j]] for j in range(k_best)] \n",
    "#     A_elite = [actions[argsort_[j]] for j in range(k_best)]\n",
    "#     #select elite trajectories\n",
    "#     # Tr_elite = trajectories\n",
    "#     # A_elite = actions\n",
    "\n",
    "#     p_loss_ = np.mean(L_vec)\n",
    "#     policy_loss_vec[n] = p_loss_\n",
    "\n",
    "#     if p_loss_ <= current_best_loss:\n",
    "#         current_best_PI = copy.deepcopy(PI)\n",
    "#         current_best_loss = p_loss_\n",
    "#     #update policy\n",
    "#     PI_new = make_new_PI(lambda_,N1,N2,M,s1_grid,s2_grid,a1_grid,Tr_elite,A_elite)\n",
    "\n",
    "#     PI = (1-epsilon_)*PI_new + epsilon_*PI\n",
    "\n",
    "#     # print('policy loss {}'.format(p_loss_))\n",
    "\n",
    "\n",
    "#     # if n ==0 :\n",
    "\n",
    "#     #     #update policy\n",
    "#     #     PI_new = make_new_PI(lambda_,N1,N2,M,s1_grid,s2_grid,a1_grid,Tr_elite,A_elite)\n",
    "#     #     PI = (1-epsilon_)*PI_new + epsilon_*PI\n",
    "#     #     last_best_loss = p_loss_\n",
    "#     #     print('policy loss {}'.format(p_loss_))\n",
    "#     # elif p_loss_ <= last_best_loss:\n",
    "#     #     last_best_loss = p_loss_\n",
    "#     #     #update policy\n",
    "#     #     PI_new = make_new_PI(lambda_,N1,N2,M,s1_grid,s2_grid,a1_grid,Tr_elite,A_elite)\n",
    "\n",
    "#     #     PI = (1-epsilon_)*PI_new + epsilon_*PI\n",
    "\n",
    "#     #     print('policy loss {}'.format(p_loss_))\n",
    "# PI = current_best_PI"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
